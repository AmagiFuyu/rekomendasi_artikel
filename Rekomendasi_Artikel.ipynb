{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sistem Rekomendasi Artikel Menggunakan Content-Based Filtering\n",
        "# 1. Pendahuluan\n",
        "Notebook ini berisi implementasi sistem rekomendasi artikel menggunakan pendekatan Content-Based Filtering.\n",
        "Pendekatan ini bekerja dengan cara merekomendasikan artikel yang memiliki kemiripan konten dengan artikel yang telah dibaca pengguna.\n",
        "Dataset diambil dari Kaggle: https://www.kaggle.com/datasets/jainilcoder/article-recommendation-system"
      ],
      "metadata": {
        "id": "ZfKGa84G9hcl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Import Library\n",
        "Tahap ini mengimpor seluruh pustaka yang dibutuhkan, seperti pandas untuk manipulasi data,\n",
        "nltk untuk preprocessing teks, dan scikit-learn untuk vektorisasi serta penghitungan kemiripan antar dokumen."
      ],
      "metadata": {
        "id": "riVT68Ti9wRD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGY6SuNv9KZw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download NLTK\n",
        "Mendwonload korpus \"stopwords\" dari library NLTK"
      ],
      "metadata": {
        "id": "lcKeUn35BKeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "aKk7rEPLBNEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Load Dataset\n",
        "Memuat Dataset Artikel, Struktur dataset terdiri dari dua kolom utama:\n",
        "\n",
        "1. `'Titles'`\n",
        "\n",
        "2. `'Article'.`"
      ],
      "metadata": {
        "id": "2qlqX2Ha97AM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/articles.csv', encoding='latin1')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "qraK7F_O-uSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Explatory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "OPdQeApx_lq7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Melihat Informasi Data\n",
        " Menampilkan ringkasan informasi DataFrame, termasuk tipe data dan jumlah nilai non-null."
      ],
      "metadata": {
        "id": "UbgRTOIp_s6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info())"
      ],
      "metadata": {
        "id": "lZ1R3gHp_jUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Menangani Missing Values\n",
        "Menghitung dan menampilkan jumlah nilai yang hilang (NaN) di setiap kolom DataFrame."
      ],
      "metadata": {
        "id": "cmAHhd7t_1jV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "DGomyOd9_08r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Melihat Sampel\n",
        "Menampilkan 5 Sampel dari DataFrame"
      ],
      "metadata": {
        "id": "5XOn9dl2_7J6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.sample(5))"
      ],
      "metadata": {
        "id": "fY4yaCoEAaUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Preprocessing\n",
        "Tahapan ini bertujuan membersihkan teks dari karakter tidak penting,\n",
        "menghapus stopwords, dan melakukan stemming untuk mendapatkan bentuk kata dasar.\n",
        "Gabungan antara kolom judul dan isi artikel digunakan sebagai basis fitur teks.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "h6LsuO0CA0wy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def preprocess(text):\n",
        "    text = str(text).lower()  # ubah ke huruf kecil\n",
        "    text = re.sub(r'\\d+', '', text)  # hapus angka\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # hapus tanda baca\n",
        "    tokens = text.split()\n",
        "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]  # hapus stopwords dan stemming\n",
        "    return ' '.join(tokens)"
      ],
      "metadata": {
        "id": "xw32eyT_A_KH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Menggabungkan judul dan isi artikel\n",
        "menggabungkan kolom `'Titles'` dan `'Article'` menjadi kolom `'text'`. Kemudian, membersihkan teks di kolom `'text'` menggunakan fungsi preprocess dan menyimpannya di kolom `'text_clean'`."
      ],
      "metadata": {
        "id": "oJSy1qNABSDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['Title'] + \" \" + df['Article']\n",
        "df['text_clean'] = df['text'].apply(preprocess)"
      ],
      "metadata": {
        "id": "ZmF2Ed7TBXoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Feature Extraction\n",
        " Melakukan Ektraksi Fitur, TF-IDF (Term Frequency-Inverse Document Frequency) digunakan untuk mengubah teks menjadi vektor numerik\n",
        " berdasarkan frekuensi kemunculan kata dalam dokumen relatif terhadap seluruh korpus."
      ],
      "metadata": {
        "id": "c8WgtOxmC53T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf.fit_transform(df['text_clean'])"
      ],
      "metadata": {
        "id": "5l09UoSAC8qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Similarity Calculation\n",
        "Cosine similarity digunakan untuk mengukur tingkat kemiripan antar dua artikel berdasarkan vektor TF-IDF.\n",
        "\n",
        "Nilainya berkisar antara 0 (tidak mirip) hingga 1 (sangat mirip)."
      ],
      "metadata": {
        "id": "VZJ6CtbFDxlj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cos_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)"
      ],
      "metadata": {
        "id": "qDZSw7IDDkfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Rekomendasi Artikel\n",
        "Fungsi get_recommendations menerima indeks artikel dan mengembalikan daftar top-n artikel paling mirip berdasarkan skor cosine similarity. Artikel input akan dilewati dalam hasil."
      ],
      "metadata": {
        "id": "5PJyeBhEE01a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recommendations(index, top_n=10):\n",
        "    sim_scores = list(enumerate(cos_sim[index]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:top_n+1]  # Skip artikel itu sendiri\n",
        "    article_indices = [i[0] for i in sim_scores]\n",
        "    return df.iloc[article_indices][['Title']]\n",
        "\n",
        "# Contoh rekomendasi\n",
        "article_id = 10\n",
        "print(\"Artikel utama:\")\n",
        "print(df.iloc[article_id]['Title'])\n",
        "print(\"\\nRekomendasi artikel:\")\n",
        "print(get_recommendations(article_id))\n"
      ],
      "metadata": {
        "id": "Pk6wxCG5Ecd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Evaluasi\n",
        "Evaluasi dilakukan dengan cara observasi manual terhadap hasil rekomendasi artikel.\n",
        "\n",
        "Contoh:\n",
        "\n",
        "Best Books to Learn Computer Vision\n",
        "\n",
        "Rekomendasi yang dihasilkan:\n",
        "1. Best Books to Learn NLP\n",
        "2. Best Books to Learn Deep Learning\n",
        "3. Best Books to Learn Data Analysis\n",
        "4. Best Python Frameworks to Build APIs\n",
        "5. Best Resources to Learn Python\n",
        "6. Voice Recorder using Python\n",
        "7. Multiclass Classification Algorithms in Machine Learning\n",
        "8. Applications of Deep Learning\n",
        "9. Apple Stock Price Prediction with Machine Learning\n",
        "10. Use Cases of Different Machine Learning Algorithms\n",
        "\n",
        "Analisis:\n",
        "- Mayoritas artikel yang direkomendasikan masih dalam topik yang berkaitan dengan *Machine Learning*, *Deep Learning*, dan *Python*, yang secara tematik memang berhubungan dengan Computer Vision.\n",
        "\n",
        "- Judul-judul seperti “Best Books to Learn NLP” dan “Best Books to Learn Deep Learning” menunjukkan bahwa sistem berhasil mengenali pola dari artikel dengan format judul yang mirip dan konten serupa.\n",
        "\n",
        "- Ini menunjukkan bahwa pendekatan Content-Based Filtering dengan TF-IDF dan cosine similarity bekerja cukup efektif pada dataset ini.\n",
        "\n",
        "Keterbatasan:\n",
        "- Karena tidak ada label relevansi atau interaksi pengguna, tidak bisa dihitung metrik seperti Precision@k atau Recall.\n",
        "\n",
        "- Rekomendasi bersifat statis, belum mempertimbangkan preferensi atau histori pengguna.\n",
        "\n",
        "Kesimpulan Evaluasi:\n",
        "\n",
        "1. Rekomendasi yang diberikan cukup relevan dan kontekstual terhadap artikel sumber.\n",
        "\n",
        "2. Evaluasi berbasis pengamatan ini cukup untuk memvalidasi pendekatan content-based filtering pada kasus ini."
      ],
      "metadata": {
        "id": "4vL1kasvFihr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Kesimpulan\n",
        "Proyek ini berhasil membangun sistem rekomendasi artikel menggunakan pendekatan Content-Based Filtering\n",
        "berdasarkan kemiripan konten antarartikel. Metode yang digunakan meliputi:\n",
        "\n",
        "- Preprocessing teks: pembersihan teks, penghapusan stopwords, dan stemming.\n",
        "- Ekstraksi fitur: TF-IDF Vectorizer digunakan untuk merepresentasikan artikel dalam bentuk vektor numerik.\n",
        "- Penghitungan kemiripan: cosine similarity menghitung tingkat kemiripan antar artikel.\n",
        "\n",
        "Hasil evaluasi menunjukkan bahwa sistem mampu menghasilkan rekomendasi artikel yang relevan secara tematik\n",
        "terhadap artikel acuan. Sebagai contoh, untuk artikel berjudul \"Best Books to Learn Computer Vision\", sistem\n",
        "berhasil merekomendasikan artikel lain yang membahas buku-buku pembelajaran terkait bidang NLP, Deep Learning,\n",
        "dan Python, yang masih dalam satu ranah keilmuan.\n",
        "\n",
        "Kelebihan:\n",
        "- Tidak memerlukan data interaksi pengguna.\n",
        "\n",
        "- Efektif pada kasus dengan teks deskriptif yang kaya informasi.\n",
        "\n",
        "Keterbatasan:\n",
        "- Rekomendasi bersifat statis dan belum mempertimbangkan preferensi pengguna secara personal.\n",
        "\n",
        "- Tidak tersedia metrik kuantitatif untuk evaluasi (seperti precision@k), karena dataset tidak menyertakan label relevansi.\n",
        "\n",
        "Rekomendasi Pengembangan:\n",
        "- Menggabungkan pendekatan ini dengan metode collaborative filtering jika data pengguna tersedia.\n",
        "\n",
        "- Menyediakan antarmuka input berdasarkan judul artikel untuk kenyamanan pengguna.\n",
        "\n",
        "Dengan pendekatan content-based ini, sistem rekomendasi dapat digunakan sebagai solusi awal yang sederhana namun efektif\n",
        "untuk menyajikan artikel serupa kepada pembaca berdasarkan isi kontennya.\n"
      ],
      "metadata": {
        "id": "Sr1BVq0DGabz"
      }
    }
  ]
}